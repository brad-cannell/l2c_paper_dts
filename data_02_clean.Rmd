---
title: "Clean data for DTS paper"
date: "2021-04-20 <br> Updated: `r Sys.Date()`"
---

# ‚≠êÔ∏èOverview

**2021-03-11, from Michael Businelle**

Hi Michael. Here are the analyses that we would like you to run for the first Link2Care paper.

**2021-04-16, Meeting with Michael Businelle**

- IV‚Äôs: 4 DTS sub scales
- DV‚Äôs: depression, hostility, urban life stress, and aggression
- Adjust: Same as before
- Add these new analyses to the existing word document

![](img/var_table.png)

**NOTE on source data**

Eventually, it would be nice to use the single, complete analysis data set that we are creating. For now, there is a ton of data management in this code.

# üì¶Load packages

```{r message=FALSE}
library(dplyr, warn.conflicts = FALSE)
library(haven, warn.conflicts = FALSE)
library(readr, warn.conflicts = FALSE)
```

# üåéConnect to UTH server 

```{bash}
# Don't drill all the way down to live documents because not all of the data is in live documents.
open 'smb://islgpcifs.uthouston.edu/sph_research/Link2Care/'
```

# üì•Import data 

Below, we run the file, data_survey_01_import.Rmd, which is used to import the Link2Care follow-up visit survey data and do some initial data cleaning (e.g., create calculated variables).

```{r message=FALSE}
source("R/source_rmd.R")
source_rmd("data_survey_01_import.Rmd")
rm(source_rmd)
# 2021-11-09: v1 imported with 324 rows and 810 columns.
# 2021-11-09: v2 imported with 299 rows and 213 columns.
# 2021-11-09: v3 imported with 214 rows and 542 columns.
# 2021-11-09: v4 imported with 155 rows and 598 columns.
# 2021-11-09: v5 imported with 137 rows and 649 columns.
# 2021-11-09: REDCap imported with 24 rows and 3 columns.
# 2021-11-09: Master log screened in imported with 327 rows and 41 columns.
# 2021-11-09: 328 participants have been randomized to a treatment group.
# 2021-11-09: The all_visits data frame was created and cleaned in data_survey_01_import.Rds with 325 rows and 2924 columns.
```


# üößData management 

Only do data management in this file that applies to this analysis only. If the data management task is likely to be more broadly applicable, then add it to data_survey_01_import.Rmd.

## Keep columns of interest

![](img/var_table.png)

This isn't strictly necessary, but it makes the data easier to work with.

```{r}
dts_df <- all_visits %>%
  select(
    id, group, dts_total_v2, PHQ_dep_dichot_total, gad_7_total_v1, 
    aggression_total, tcu_hs_v2_total, uls_v2_total, ddd_v1_total, 
    pv_violence_victim_30_f, pv_witness_violence_30, pv_witness_violence_30_f,
    pv_witness_violence_6, pv_witness_violence_6_f,
    ise_appraisal_v1, ise_belonging_v1, ise_tangable_v1, age, gender_v1_f, 
    race, race_f, hispanic, hispanic_f, edu_19_cat, edu_19_cat_f, 
    homeless_current_total, homeless_time_total, dts_tolerance_v2,
    dts_absorption_v2, dts_appraisal_v2, dts_regulation_v2, mms_total,
    homeless_mental_treatment_f, phq_8_total, phq_8_gt_10_f
  )
```

```{r}
dim(dts_df) # 325  35
```

## Filter out rows in the table

2020-12-08, from Michael: Can you start by recreating a baseline table with all the variables below (use all participants to date that have completed the baseline and randomization visits)?

2021-01-20: Michael said to consider visit 2 answers to be "baseline" answers for questions that weren't asked at visit 1.

Select people who were randomized only. First, coerce group to a factor. 

```{r}
dts_df <- dts_df %>% 
  mutate(group = factor(group, c("UCM", "UCM+SP", "L2C")))
```

```{r}
dts_df <- dts_df %>% 
  filter(group %in% c("UCM", "UCM+SP", "L2C"))
```

```{r}
dim(dts_df) # 298  35
```

**NOTE on number of randomized people**
2021-03-16: When we import the data above, it says that 250 were randomized. However, there are only 245 people remaining when we filter out people who are not assigned to a group in the data above. I did some digging in data_survey_01_import.Rmd, and found that there are 5 people in the Master Log (2265, 2266, 2267, 2268, 2269) that don't appear in the QDS data. It appears as though this is just because the QDS data hasn't been downloaded recently. I'm going to just push ahead for now.


## üßÆRecode/calculate variables

### Social support total

```{r}
dts_df <- dts_df %>% 
  mutate(ise_total = ise_appraisal_v1 + ise_belonging_v1 + ise_tangable_v1)
```

### Race/Ethnicity

```{r}
dts_df <- dts_df %>% 
  mutate(
    race_eth_4_cat = case_when(
      hispanic_f == "Yes" ~ 3, # Hispanic, any race
      race == 2 ~ 1, # White, non-Hispanic
      race == 3 ~ 2, # Black, non-Hispanic
      TRUE ~ 4 # Other race, non-Hispanic
    ),
    race_eth_4_cat_f = factor(
      race_eth_4_cat, 1:4, c(
        "White, non-Hispanic", "Black, non-Hispanic", "Hispanic, any race",
        "Other race, non-Hispanic"
      )
    )
  )
```

### Education

```{r}
dts_df <- dts_df %>% 
  mutate(
    high_school_grad = if_else(edu_19_cat < 12, 0, 1),
    high_school_grad_f = factor(high_school_grad, 0:1, c("No", "Yes"))
  )
```

```{r}
dim(dts_df) # 298  40
```


# Export analysis data

Export the analysis data as an SPSS data file for Michael and upload it to Kiteworks and the U drive.

We also need to export and rds file to use for analysis in R. Otherwise, the factors are lost.

```{r}
write_sav(
  dts_df, 
  "/Volumes/Link2Care/Statistical Projects/Robison - Distress Tolerance Scale Paper/dts_paper.sav"
)
```

```{r}
write_rds(
  dts_df, 
  "/Volumes/Link2Care/Statistical Projects/Robison - Distress Tolerance Scale Paper/dts_paper.rds"
)
```


```{r echo=FALSE}
sessionInfo()
```

